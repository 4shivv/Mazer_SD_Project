PORT=4000
OLLAMA_HOST=http://localhost:11434
# Model to use for chat (must be pulled first: ollama pull <model>). Examples: llama3.2:3b, llama2:7b, mistral
OLLAMA_MODEL=llama3.2:3b
